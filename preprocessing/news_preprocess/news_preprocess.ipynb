{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f3f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d726b77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ekonlpy\n",
      "  Downloading ekonlpy-2.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click>=8.1.6 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from ekonlpy) (8.1.8)\n",
      "Collecting fugashi>=1.3.3 (from ekonlpy)\n",
      "  Downloading fugashi-1.5.2-cp39-cp39-win_amd64.whl.metadata (7.5 kB)\n",
      "Collecting mecab-ko-dic>=1.0.0 (from ekonlpy)\n",
      "  Downloading mecab-ko-dic-1.0.0.tar.gz (33.2 MB)\n",
      "     ---------------------------------------- 0.0/33.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 2.1/33.2 MB 9.0 MB/s eta 0:00:04\n",
      "     --------------- ----------------------- 12.8/33.2 MB 31.0 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 23.1/33.2 MB 36.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  32.8/33.2 MB 38.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 33.2/33.2 MB 36.9 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: nltk>=3.8.1 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from ekonlpy) (3.9.2)\n",
      "Collecting pandas<=2.3.2,>=1.5.3 (from ekonlpy)\n",
      "  Downloading pandas-2.3.2-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy<=1.13.1,>1.10.0 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from ekonlpy) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from pandas<=2.3.2,>=1.5.3->ekonlpy) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from pandas<=2.3.2,>=1.5.3->ekonlpy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from pandas<=2.3.2,>=1.5.3->ekonlpy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from pandas<=2.3.2,>=1.5.3->ekonlpy) (2025.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from click>=8.1.6->ekonlpy) (0.4.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from nltk>=3.8.1->ekonlpy) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from nltk>=3.8.1->ekonlpy) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from nltk>=3.8.1->ekonlpy) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hg432\\anaconda3\\envs\\nlp_study\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<=2.3.2,>=1.5.3->ekonlpy) (1.17.0)\n",
      "Downloading ekonlpy-2.2.0-py3-none-any.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "   -------------------------------------- - 10.0/10.3 MB 47.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 45.6 MB/s  0:00:00\n",
      "Downloading pandas-2.3.2-cp39-cp39-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 6.0/11.3 MB 28.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 33.7 MB/s  0:00:00\n",
      "Downloading fugashi-1.5.2-cp39-cp39-win_amd64.whl (509 kB)\n",
      "Building wheels for collected packages: mecab-ko-dic\n",
      "  Building wheel for mecab-ko-dic (pyproject.toml): started\n",
      "  Building wheel for mecab-ko-dic (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for mecab-ko-dic: filename=mecab_ko_dic-1.0.0-py3-none-any.whl size=33424458 sha256=87ba44ece365411cd8bfba948d5049e83586fef5b05a6638de0304655c25cb7f\n",
      "  Stored in directory: c:\\users\\hg432\\appdata\\local\\pip\\cache\\wheels\\1e\\26\\c0\\ed4c061096b1480abefe1e2a0356543bf7a38f61c037b69ab6\n",
      "Successfully built mecab-ko-dic\n",
      "Installing collected packages: mecab-ko-dic, fugashi, pandas, ekonlpy\n",
      "\n",
      "   ---------------------------------------- 0/4 [mecab-ko-dic]\n",
      "   ---------------------------------------- 0/4 [mecab-ko-dic]\n",
      "  Attempting uninstall: pandas\n",
      "   ---------------------------------------- 0/4 [mecab-ko-dic]\n",
      "    Found existing installation: pandas 2.3.3\n",
      "   ---------------------------------------- 0/4 [mecab-ko-dic]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "    Uninstalling pandas-2.3.3:\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "      Successfully uninstalled pandas-2.3.3\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   -------------------- ------------------- 2/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [ekonlpy]\n",
      "   ---------------------------------------- 4/4 [ekonlpy]\n",
      "\n",
      "Successfully installed ekonlpy-2.2.0 fugashi-1.5.2 mecab-ko-dic-1.0.0 pandas-2.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hg432\\anaconda3\\envs\\nlp_study\\Lib\\site-packages\\~andas.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hg432\\anaconda3\\envs\\nlp_study\\Lib\\site-packages\\~andas'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install ekonlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d0df869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_news(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # HTML 태그 제거\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # 기자 이메일, 언론사 이름 제거\n",
    "    text = re.sub(r'\\[.+?기자\\]|\\[.+?뉴스\\]|\\[.+?제공\\]', '', text)\n",
    "    text = re.sub(r'\\/사진제공?=.+?$', '', text)\n",
    "    text = re.sub(r'\\/사진?=.+?$', '', text)\n",
    "    \n",
    "    # 홍보 문구 제거\n",
    "    text = re.sub(r'이\\s*기사는\\s*.+?\\s*에\\s*게재된\\s*기사입니다\\.', '', text)\n",
    "\n",
    "    # 줄바꿈 공백으로\n",
    "    text = text.replace('\\u2028', ' ').replace('\\u2029', ' ').replace('\\n', ' ')\n",
    "    \n",
    "    # 한글, 영어, 숫자, 공백, 마침표만 남기기 (마침표는 문장 구분을 위해 남겨야 함)\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s\\.]', ' ', text)\n",
    "    \n",
    "    # 연속된 공백 하나로 줄이기\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "822f092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71236/71236 [00:03<00:00, 21872.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 매일경제 처리 완료 (71236건)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89012/89012 [00:05<00:00, 17015.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 머니투데이 처리 완료 (89012건)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79208/79208 [00:04<00:00, 19770.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 한국경제 처리 완료 (79208건)\n",
      "\n",
      "✨ 총 239456건의 '뉴스' 데이터 저장 완료\n"
     ]
    }
   ],
   "source": [
    "# 여러 언론사 클렌징 데이터 합치기\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "folder_path = '../../db/news_contents/news_contents_*.csv'\n",
    "file_list = glob.glob(folder_path)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in file_list:\n",
    "    filename = os.path.basename(file)\n",
    "    source_name = filename.split('_')[-1].replace('.csv', '')\n",
    "\n",
    "    df = pd.read_csv(file, usecols=['date', 'content'])\n",
    "\n",
    "    # 오염 데이터 제거용\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.dropna(subset=['date'])\n",
    "\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df['date'] = pd.to_datetime(df['date'])\n",
    "    temp_df['date'] = temp_df['date'].dt.date\n",
    "\n",
    "    temp_df['content'] = df['content'].progress_apply(clean_news)\n",
    "    temp_df['tokens'] = ''\n",
    "    temp_df['category'] = '뉴스'\n",
    "    temp_df['source'] = source_name\n",
    "\n",
    "    all_data.append(temp_df)\n",
    "    print(f\"✔ {source_name} 처리 완료 ({len(temp_df)}건)\")\n",
    "\n",
    "if all_data:\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df[['date', 'content', 'tokens', 'category', 'source']]\n",
    "    final_df.to_csv('news_preprocessed_integrated.csv', index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n✨ 총 {len(final_df)}건의 '뉴스' 데이터 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb7b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekonlpy.sentiment import MPCK\n",
    "\n",
    "mpck = MPCK()\n",
    "\n",
    "def get_tokens(text):\n",
    "    try:\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        tokens = mpck.tokenize(text)\n",
    "        ngrams = mpck.ngramize(tokens)\n",
    "        final_result = tokens + ngrams    \n",
    "        return \", \".join(final_result)\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afaf521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20만 건 토큰화 시작 (시간이 다소 소요됩니다) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:03<00:00, 82.99it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(\"--- 20만 건 토큰화 시작 (시간이 다소 소요됩니다) ---\")\n",
    "tqdm.pandas()\n",
    "final_df['tokens'] = final_df['content'].progress_apply(get_tokens)\n",
    "\n",
    "final_df.to_csv('news_preprocessed_with_tokens.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f33f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>14일 서울 중구 하나은행 본점 딜링룸 현황판에 코스피가 표시돼 있다. 나흘 연속 ...</td>\n",
       "      <td>중구/NNG, 본점/NNG, 딜링룸/NNG, 현황/NNG, 판/NNG, 코스피/NN...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>매일경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-21</td>\n",
       "      <td>NH농협은행이 수탁 중인 전국 광역자치단체 금고의 예치액에 대한 금리가 최대 1.2...</td>\n",
       "      <td>수탁/NNG, 중/NNG, 전국/NNG, 금고/NNG, 예치/NNG, 액/NNG, ...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>매일경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-18</td>\n",
       "      <td>유럽중앙은행 ECB 이 18일 현지시간 예금금리를 비롯한 3대 정책금리를 모두 동결...</td>\n",
       "      <td>ecb/NNG, ecb/NNG, 현지/NNG, 예금/NNG, 금리/NNG, 비롯/N...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>매일경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-12-14</td>\n",
       "      <td>은행채 금리상승에 조달비용 대형증권사 IMA 출시도 변수 증권사 머니무브 차단 목적...</td>\n",
       "      <td>은행채/NNG, 금리/NNG, 상승/NNG, 조달/NNG, 비용/NNG, 출시/NN...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>매일경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>비트코인 급락에 스트레티지도 60 폭락 MSCI 나스닥100등 벤치마크 제외가능성 ...</td>\n",
       "      <td>비트코인/NNG, 급락/NNG, 하락/NNG, msci/NNG, 나스닥100/NNG...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>매일경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>미 기준금리 0.25 포인트 인하 환율 하락 출발 제롬 파월 미 중앙은행 Fed 의...</td>\n",
       "      <td>미/NNG, 금리/NNG, 포인트/NNG, 인하/NNG, 환율/NNG, 하락/NNG...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>한국경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2025-12-04</td>\n",
       "      <td>사진 연합뉴스 간밤 뉴욕증시가 기술주 없는 상승 을 선보였다. 부진한 고용지표를 바...</td>\n",
       "      <td>간밤/NNG, 없/VA, 상승/NNG, 선보였/VV, 부진/NNG, 고용/NNG, ...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>한국경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>Fed 3연속 금리 인하 위원 3명 반대 이례적 2명 동결 1명 빅컷 주장 3명 반...</td>\n",
       "      <td>fed/NNG, 연속/NNG, 금리/NNG, 인하/NNG, 반대/NNG, 이례적/V...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>한국경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2025-12-15</td>\n",
       "      <td>사진 뉴스1 국내 증시는 이번주 반도체 풍향계 마이크론 실적 발표를 앞두고 변동성을...</td>\n",
       "      <td>뉴스/NNG, 증시/NNG, 주/NNG, 풍향계/NNG, 실적발표/NNG, 앞두/V...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>한국경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2025-12-22</td>\n",
       "      <td>금 4 400달러돌파 은 70달러 육박 구리 12 000달러 넘어 금리인하 기대에 ...</td>\n",
       "      <td>달러/NNG, 돌파/NNG, 달러/NNG, 육박/NNG, 달러/NNG, 넘/VV, ...</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>한국경제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            content  \\\n",
       "0    2025-11-14  14일 서울 중구 하나은행 본점 딜링룸 현황판에 코스피가 표시돼 있다. 나흘 연속 ...   \n",
       "1    2025-10-21  NH농협은행이 수탁 중인 전국 광역자치단체 금고의 예치액에 대한 금리가 최대 1.2...   \n",
       "2    2025-12-18  유럽중앙은행 ECB 이 18일 현지시간 예금금리를 비롯한 3대 정책금리를 모두 동결...   \n",
       "3    2025-12-14  은행채 금리상승에 조달비용 대형증권사 IMA 출시도 변수 증권사 머니무브 차단 목적...   \n",
       "4    2025-11-22  비트코인 급락에 스트레티지도 60 폭락 MSCI 나스닥100등 벤치마크 제외가능성 ...   \n",
       "..          ...                                                ...   \n",
       "295  2025-12-11  미 기준금리 0.25 포인트 인하 환율 하락 출발 제롬 파월 미 중앙은행 Fed 의...   \n",
       "296  2025-12-04  사진 연합뉴스 간밤 뉴욕증시가 기술주 없는 상승 을 선보였다. 부진한 고용지표를 바...   \n",
       "297  2025-12-11  Fed 3연속 금리 인하 위원 3명 반대 이례적 2명 동결 1명 빅컷 주장 3명 반...   \n",
       "298  2025-12-15  사진 뉴스1 국내 증시는 이번주 반도체 풍향계 마이크론 실적 발표를 앞두고 변동성을...   \n",
       "299  2025-12-22  금 4 400달러돌파 은 70달러 육박 구리 12 000달러 넘어 금리인하 기대에 ...   \n",
       "\n",
       "                                                tokens category source  \n",
       "0    중구/NNG, 본점/NNG, 딜링룸/NNG, 현황/NNG, 판/NNG, 코스피/NN...       뉴스   매일경제  \n",
       "1    수탁/NNG, 중/NNG, 전국/NNG, 금고/NNG, 예치/NNG, 액/NNG, ...       뉴스   매일경제  \n",
       "2    ecb/NNG, ecb/NNG, 현지/NNG, 예금/NNG, 금리/NNG, 비롯/N...       뉴스   매일경제  \n",
       "3    은행채/NNG, 금리/NNG, 상승/NNG, 조달/NNG, 비용/NNG, 출시/NN...       뉴스   매일경제  \n",
       "4    비트코인/NNG, 급락/NNG, 하락/NNG, msci/NNG, 나스닥100/NNG...       뉴스   매일경제  \n",
       "..                                                 ...      ...    ...  \n",
       "295  미/NNG, 금리/NNG, 포인트/NNG, 인하/NNG, 환율/NNG, 하락/NNG...       뉴스   한국경제  \n",
       "296  간밤/NNG, 없/VA, 상승/NNG, 선보였/VV, 부진/NNG, 고용/NNG, ...       뉴스   한국경제  \n",
       "297  fed/NNG, 연속/NNG, 금리/NNG, 인하/NNG, 반대/NNG, 이례적/V...       뉴스   한국경제  \n",
       "298  뉴스/NNG, 증시/NNG, 주/NNG, 풍향계/NNG, 실적발표/NNG, 앞두/V...       뉴스   한국경제  \n",
       "299  달러/NNG, 돌파/NNG, 달러/NNG, 육박/NNG, 달러/NNG, 넘/VV, ...       뉴스   한국경제  \n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
