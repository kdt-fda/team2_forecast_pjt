import sys
import os
import time

# [1. í•„ìˆ˜ íŒ¨ì¹˜] ìœˆë„ìš°ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ íŒŒì¼ ì½ê¸° ì—ëŸ¬ ë°©ì§€
if sys.platform == 'win32':
    import _io
    def _patched_open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None):
        if 'b' not in mode and encoding is None:
            encoding = 'utf-8'
        return _io.open(file, mode, buffering, encoding, errors, newline, closefd, opener)
    import builtins
    builtins.open = _patched_open

# UTF-8 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['PYTHONUTF8'] = '1'

import pandas as pd
from ekonlpy.sentiment import MPCK
from tqdm import tqdm

# --- [2. ngramize í•¨ìˆ˜] ---
def ngramize(tokens, max_n=5):
    keep_tags = ['NNG', 'VA', 'VAX', 'MAG', 'VV']
    filtered = [w for w in tokens if w.split('/')[1] in keep_tags]
    all_ngrams = []
    for pos in range(len(filtered)):
        for n in range(1, max_n + 1):
            if pos + n <= len(filtered):
                ngram = ";".join(filtered[pos : pos + n])
                all_ngrams.append({'ngram': ngram, 'start': pos, 'end': pos + n, 'len': n})
                
    final_ngrams = []
    sorted_ngrams = sorted(all_ngrams, key=lambda x: x['len'], reverse=True)
    covered_ranges = set()
    for ngram in sorted_ngrams:
        is_covered = False
        for i in range(ngram['start'], ngram['end']):
            if i in covered_ranges:
                is_covered = True
                break
        if not is_covered:
            final_ngrams.append(ngram['ngram'])
            for i in range(ngram['start'], ngram['end']):
                covered_ranges.add(i)
    return final_ngrams

# --- [3. MPCK ì„ ì–¸ ë° í† í°í™” í•¨ìˆ˜] ---
# íŒ¨ì¹˜ ì ìš© í›„ì— ì„ ì–¸í•´ì•¼ ì•ˆì „í•©ë‹ˆë‹¤.
mpck = MPCK()

def get_final_tokens(text):
    if pd.isna(text) or text == "":
        return []
    try:
        basic_tokens = mpck.tokenize(text)
        return ngramize(basic_tokens, max_n=5)
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥ í›„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []

# --- [4. ì‹¤í–‰ ë¡œì§] ---
if __name__ == "__main__":
    # ì „ì²´ ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
    
    tqdm.pandas()

    # KSSê°€ ì´ë¯¸ ì™„ë£Œëœ íŒŒì¼ ë¡œë“œ
    SENTENCE_FILE = 'df_sentences_timetest.parquet'
    
    if os.path.exists(SENTENCE_FILE):
        print(f"ğŸ“‚ KSS ì „ì²˜ë¦¬ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤: {SENTENCE_FILE}")
        df_sentences = pd.read_parquet(SENTENCE_FILE)
    
        
        print(f"ğŸ§  ì´ {len(df_sentences)}ê±´ì˜ ë¬¸ì¥ì— ëŒ€í•´ ì‹±ê¸€ ì½”ì–´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        total_start = time.time()
        # ë‹¨ì¼ í”„ë¡œì„¸ì‹± ì‹¤í–‰ (progress_applyë¡œ ì§„í–‰ ë°” í‘œì‹œ)
        df_sentences['tokens'] = df_sentences['content'].progress_apply(get_final_tokens)
        total_end = time.time()
        
        # ìƒìœ„ 10ê°œ ê²°ê³¼ í™•ì¸ìš© ì¶œë ¥
        print("\nğŸ” ë¶„ì„ ê²°ê³¼ ìƒ˜í”Œ:")
        print(df_sentences[['content', 'tokens']].head(10))
        
    else:
        print(f"âŒ '{SENTENCE_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. KSS ì „ì²˜ë¦¬ íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")

    # ì„±ëŠ¥ ì¸¡ì • ì¢…ë£Œ
 
    total_minutes = (total_end - total_start) / 60

    print("-" * 40)
    print(f"âœ¨ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"â±ï¸ ì‹±ê¸€ í”„ë¡œì„¸ìŠ¤ ì´ ì†Œìš” ì‹œê°„: {total_minutes:.2f}ë¶„")
    print("-" * 40)